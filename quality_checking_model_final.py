# -*- coding: utf-8 -*-
"""quality_checking_model_final.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1F5g--0oYknwZxV4v8bNkeFFuXGPQ-DXr
"""

from google.colab import drive
drive.mount('/content/drive')

"""### Import all the Dependencies"""

import tensorflow as tf
from tensorflow.keras import models, layers
import matplotlib.pyplot as plt
from IPython.display import HTML

BATCH_SIZE = 64
IMAGE_SIZE = 256
CHANNELS=3
EPOCHS=20

"""### Set all the Constants

### Import data into tensorflow dataset object
"""

dataset = tf.keras.preprocessing.image_dataset_from_directory(
    "/content/drive/MyDrive/resnet_analysis_new/train",
    seed=123,
    shuffle=True,
    image_size=(IMAGE_SIZE,IMAGE_SIZE),
    batch_size=BATCH_SIZE
)

class_names = dataset.class_names
class_names

for image_batch, labels_batch in dataset.take(1):
    print(image_batch.shape)
    print(labels_batch.numpy())

"""### Visualize some of the images from our dataset"""

plt.figure(figsize=(40, 40))
for image_batch, labels_batch in dataset.take(1):
    for i in range(12):
        ax = plt.subplot(3, 4, i + 1)
        plt.imshow(image_batch[i].numpy().astype("uint8"))
        plt.title(class_names[labels_batch[i]])
        plt.axis("off")

"""### Function to Split Dataset

Dataset should be bifurcated into 3 subsets, namely:
1. Training: Dataset to be used while training
2. Validation: Dataset to be tested against while training
3. Test: Dataset to be tested against after we trained a model
"""

len(dataset)

dataset.class_names

train_size = 0.7
len(dataset)*train_size

train_ds = dataset.take(53)
len(train_ds)               #2

53+11+11
1215/16

test_size=0.15
len(dataset)*test_size

test_ds = dataset.take(11)
len(test_ds)

val_ds = dataset.take(12)
len(val_ds)

def get_dataset_partitions_tf(ds, train_split=0.7, val_split=0.2, test_split=0.1, shuffle=True, shuffle_size=100):
    assert (train_split + test_split + val_split) == 1
    
    ds_size = len(ds)
    
    if shuffle:
        ds = ds.shuffle(shuffle_size, seed=12)
    
    train_size = int(train_split * ds_size)
    val_size = int(val_split * ds_size)
    
    train_ds = ds.take(train_size)    
    val_ds = ds.skip(train_size).take(val_size)
    test_ds = ds.skip(train_size).skip(val_size)
    
    return train_ds, val_ds, test_ds

train_ds, val_ds, test_ds = get_dataset_partitions_tf(dataset)

len(train_ds)

len(val_ds)

len(test_ds)

"""### Cache, Shuffle, and Prefetch the Dataset"""

train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)
val_ds = val_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)
test_ds = test_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)

"""## Building the Model"""

resize_and_rescale = tf.keras.Sequential([
  layers.experimental.preprocessing.Resizing(IMAGE_SIZE, IMAGE_SIZE),
  layers.experimental.preprocessing.Rescaling(1./255),
])

data_augmentation = tf.keras.Sequential([
  layers.experimental.preprocessing.RandomFlip("horizontal_and_vertical"),
  layers.experimental.preprocessing.RandomRotation(0.2), 
  layers.experimental.preprocessing.RandomZoom(0.3),
  tf.keras.layers.RandomBrightness(
    0.4, value_range=(0, 255), seed=123
),
tf.keras.layers.RandomContrast(0.4, seed=123),

])

"""#### Applying Data Augmentation to Train Dataset"""

train_ds = train_ds.map(
    lambda x, y: (data_augmentation(x, training=True), y)
).prefetch(buffer_size=tf.data.AUTOTUNE)

from keras.layers import Concatenate

inputs =tf.keras.Input((IMAGE_SIZE, IMAGE_SIZE, 3))

# inputs = (IMAGE_SIZE, IMAGE_SIZE, CHANNELS)
# n_classes = 3

from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D
from keras.models import Model

# define the input shape

# contracting path
c1 = Conv2D(16, (3, 3), activation='relu', padding='same')(inputs)
p1 = MaxPooling2D((2, 2))(c1)

c2 = Conv2D(32, (3, 3), activation='relu', padding='same')(p1)
p2 = MaxPooling2D((2, 2))(c2)

c3 = Conv2D(64, (3, 3), activation='relu', padding='same')(p2)
p3 = MaxPooling2D((2, 2))(c3)

c4 = Conv2D(128, (3, 3), activation='relu', padding='same')(p3)
p4 = MaxPooling2D((2, 2))(c4)

c5 = Conv2D(256, (3, 3), activation='relu', padding='same')(p4)

# expanding path
u6 = UpSampling2D((2, 2))(c5)
u6 = Conv2D(128, (3, 3), activation='relu', padding='same')(u6)
u6 = Concatenate()([u6, c4])

u7 = UpSampling2D((2, 2))(u6)
u7 = Conv2D(64, (3, 3), activation='relu', padding='same')(u7)
u7 = Concatenate()([u7, c3])

u8 = UpSampling2D((2, 2))(u7)
u8 = Conv2D(32, (3, 3), activation='relu', padding='same')(u8)
u8 = Concatenate()([u8, c2])

u9 = UpSampling2D((2, 2))(u8)
u9 = Conv2D(16, (3, 3), activation='relu', padding='same')(u9)
u9 = Concatenate()([u9, c1])

outputs = Conv2D(1, (1, 1), activation='sigmoid')(u9)

# create the model
model = Model(inputs=[inputs], outputs=[outputs])

# compile the model
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

model.summary()

"""### Compiling the Model
i just used `adam` Optimizer, `SparseCategoricalCrossentropy` for losses, `accuracy` as a metric
"""

model.compile(
    optimizer='adam',
    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),
    metrics=['accuracy']
)

history = model.fit(
    train_ds,
    batch_size=BATCH_SIZE,
    validation_data=val_ds,
    verbose=2,
    epochs=60,
)

scores = model.evaluate(test_ds)

"""Scores is just a list containing loss and accuracy value

### Plotting the Accuracy and Loss Curves
"""

history

history.params

history.history.keys()

"""**loss, accuracy, val loss etc are a python list containing values of loss, accuracy etc at the end of each epoch**"""

type(history.history['loss'])

len(history.history['loss'])

history.history['loss'][:5] # show loss for first 5 epochs

acc = history.history['accuracy']
val_acc = history.history['val_accuracy']

loss = history.history['loss']
val_loss = history.history['val_loss']

plt.figure(figsize=(15,5))
plt.subplot(1, 2, 1)
plt.plot(acc, label='Training Accuracy')
plt.plot(val_acc, label='Validation Accuracy')
plt.legend(loc='lower right')
plt.title('Training and Validation Accuracy')

plt.subplot(1, 2, 2)
plt.plot(loss, label='Training Loss')
plt.plot(val_loss, label='Validation Loss')
plt.legend(loc='upper right')
plt.title('Training and Validation Loss')
plt.show()

"""### Run prediction on a sample image"""

import numpy as np
for images_batch, labels_batch in test_ds.take(1):
    
    first_image = images_batch[10].numpy().astype('uint8')
    first_label = labels_batch[10].numpy()
    
    print("first image to predict")
    plt.imshow(first_image)
    print("actual label:",class_names[first_label])
    
    batch_prediction = model.predict(images_batch)
    print("predicted label:",class_names[np.argmax(batch_prediction[0])])

"""### Write a function for inference"""

def predict(model, img):
    img_array = tf.keras.preprocessing.image.img_to_array(images[i].numpy())
    img_array = tf.expand_dims(img_array, 0)

    predictions = model.predict(img_array)

    predicted_class = class_names[np.argmax(predictions[0])]
    confidence = round(100 * (np.max(predictions[0])), 2)
    return predicted_class, confidence

"""**Now run inference on few sample images**"""

plt.figure(figsize=(18, 18))
for images, labels in test_ds.take(1):
    for i in range(16):
        ax = plt.subplot(4,4, i + 1)
        plt.imshow(images[i].numpy().astype("uint8"))
        
        predicted_class, confidence = predict(model, images[i].numpy())
        actual_class = class_names[labels[i]] 
        
        plt.title(f"Actual: {actual_class},\n Predicted: {predicted_class}.\n Confidence: {confidence}%")
        
        plt.axis("off")

"""### Saving the Model
We append the model to the list of models as a new version
"""

model.save("../final_img.h5")

import os
os.getcwd()

os.chdir("/content/drive/MyDrive/Colab Notebooks")

from tensorflow.keras.models import load_model

from joblib import Parallel, delayed
import joblib
# Save the model as a pickle in a file
joblib.dump(model,'filename.pkl')

# Load the model from the file
# knn_from_joblib = joblib.load('filename.pkl')

# Use the loaded model to make predictions
# knn_from_joblib.predict(X_test)

# saving and loading the .h5 model

# save model
# model.save('gfgModel.h5')
print('Model Saved!')

# load model
model=load_model('/content/drive/MyDrive/Model/gfgModel.h5')
# savedModel.summary()

pip install gradio

from tensorflow.keras.models import Model
from tensorflow.keras.models import load_model
import gradio as gr
import numpy as np
from PIL import Image
import tensorflow as tf
import cv2
from skimage.feature import match_template
from skimage.feature import peak_local_max

template=cv2.imread('/content/drive/MyDrive/Model/template.jpg',0)

def draw(img):
  print("start")
  img_rgb =cv2.cvtColor(img,cv2.COLOR_BGR2RGB)
  img_gray = cv2.cvtColor(img_rgb, cv2.COLOR_BGR2GRAY)
  h, w = template.shape[::] 
  predicted_class, confidence = predict_img(img_rgb)
  print(predicted_class)
  if(predicted_class=='Defective'):
     sample_mt = match_template(img_gray,template)
     patch_width, patch_height = patch.shape
     for x, y in peak_local_max(sample_mt, threshold_abs=0.7):
       rect = plt.Rectangle((y, x), patch_height, patch_width, color='r',fc='none')
       img.add_patch(rect) 
     return img,predicted_class
  elif(predicted_class=="Non-defective"):
    return img,predicted_class   
  plt.imshow(img)
  return img

def predict_img(img):
    img_array = tf.keras.preprocessing.image.img_to_array(img)
    img_array = tf.expand_dims(img_array, 0)
    predictions = model.predict(img_array)
    predicted_class = class_names[np.argmax(predictions[0])]
    confidence = round(100 * (np.max(predictions[0])), 2) 
    return predicted_class,confidence

import numpy as np
for images_batch, labels_batch in train_ds.take(6):
    
    first_image = images_batch[1].numpy().astype('uint8')
    first_label = labels_batch[1].numpy()

    predicted_class, confidence = predict_img(images_batch[i].numpy()) 
    # actual_class = class_names[labels[i]]  
    # print(predicted_class,confidence)
    # print(actual_class)
    
    # # print("first image to predict")
    # # plt.imshow(first_image)
    print("actual label:",class_names[first_label])
    
    batch_prediction = model.predict(images_batch)
    print("predicted label:",class_names[np.argmax(batch_prediction[0])])

plt.figure(figsize=(15, 15))
for images, labels in test_ds.take(16):
    for i in range(16):
        ax = plt.subplot(4,4, i + 1)
        # plt.imshow(images[i].numpy().astype("uint8"))
        
        predicted_class, confidence = predict_img(images[i].numpy())
        actual_class = class_names[labels[i]] 
        
        plt.title(f"Actual: {actual_class},\n Predicted: {predicted_class}.\n Confidence: {confidence}%")
        
        plt.axis("off")

"""#UI for an model"""

!pip install -q gradio

import cv2
import matplotlib.pyplot as plt
import os

def draw(img,template):
  img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
  res = cv2.matchTemplate(img_gray, template, cv2.TM_SQDIFF)
  # For TM_SQDIFF, Good match yields minimum value; bad match yields large values
  # For all others it is exactly opposite, max value = good fit.
  plt.imshow(res, cmap='gray')
  h, w = template.shape[::] 

  min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(res)

  top_left = min_loc  #Change to max_loc for all except for TM_SQDIFF
  bottom_right = (top_left[0] + w+80, top_left[1] + h+40)

  cv2.rectangle(img, top_left, bottom_right, (255, 0, 255), 5)  #Red rectangle with thickness 2. 
  return img

import gradio as gr
import os

def im(img):
  template = cv2.imread('/content/drive/MyDrive/Model/template.jpg', 0) 
  
  out=draw(img,template)
  return out

def predict_img(img):
    hel=img
    img_array = tf.keras.preprocessing.image.img_to_array(img)
    img_array = tf.expand_dims(img_array, 0)
    predictions = model.predict(img_array)
    predicted_class = class_names[np.argmax(predictions[0])]
    confidence = round(100 * (np.max(predictions[0])), 2) 
    if(predicted_class=="Defective"):
      template = cv2.imread('/content/drive/MyDrive/Model/template.jpg', 0) 
      out=draw(img,template)
      return out,predicted_class
    else:
      return hel,predicted_class

image = gr.inputs.Image(shape=(400,400))

image = gr.inputs.Image(shape=(400,400))
gr.Interface(fn=predict_img, inputs=image, outputs=["image","text"]).launch(debug=True)